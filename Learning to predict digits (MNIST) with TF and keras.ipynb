{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ar0058/Ash/venv3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ar0058/Ash/venv3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ar0058/Ash/venv3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ar0058/Ash/venv3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ar0058/Ash/venv3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ar0058/Ash/venv3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ar0058/Ash/venv3.6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ar0058/Ash/venv3.6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ar0058/Ash/venv3.6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ar0058/Ash/venv3.6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ar0058/Ash/venv3.6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ar0058/Ash/venv3.6/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# tf.__version__\n",
    "mnist = tf.keras.datasets.mnist # 28 x 28 images of hand-written digits 0-9\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.imshow(x_train[0])\n",
    "# plt.imshow(x_train[0], cmap = plt.cm.binary)\n",
    "# plt.show()\n",
    "# print(x_train[0])\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "# print(x_train[0])\n",
    "plt.imshow(x_train[0], cmap = plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1206 16:44:21.293976 140204855052032 deprecation.py:506] From /home/ar0058/Ash/venv3.6/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.2646 - acc: 0.9228\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.1103 - acc: 0.9665\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0753 - acc: 0.9768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f839f635748>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # two rectified linear unit activation function\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax)) # output is 10 digits from 0-9\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'] )\n",
    "model.fit(x_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 47us/sample - loss: 0.0960 - acc: 0.9708\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('epic.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1206 16:44:51.398794 140204855052032 deprecation.py:506] From /home/ar0058/Ash/venv3.6/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1206 16:44:51.403276 140204855052032 deprecation.py:506] From /home/ar0058/Ash/venv3.6/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1206 16:44:51.515926 140204855052032 hdf5_format.py:263] Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('epic.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-872a9c2f0752>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Ash/venv3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0;31m# generate symbolic tensors).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     x, _, _ = self._standardize_user_data(\n\u001b[0;32m-> 1060\u001b[0;31m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ash/venv3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2556\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2557\u001b[0m         \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2558\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2559\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2560\u001b[0m       \u001b[0my_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ash/venv3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[0;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[1;32m   2774\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expects_training_arg\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2775\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2776\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2777\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2778\u001b[0m         \u001b[0;31m# This Model or a submodel is dynamic and hasn't overridden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ash/venv3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ash/venv3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0;31m# `outputs` will be the inputs to the next layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ash/venv3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ash/venv3.6/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     outputs = array_ops.reshape(\n\u001b[0;32m--> 580\u001b[0;31m         inputs, (tensor_shape.dimension_value(inputs.shape[0]) or\n\u001b[0m\u001b[1;32m    581\u001b[0m                  array_ops.shape(inputs)[0], -1))\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "predictions = new_model.predict([x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3.6",
   "language": "python",
   "name": "venv3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
